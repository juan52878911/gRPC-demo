# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Terraform + Ansible infrastructure automation project that provisions a Rancher Kubernetes cluster using Multipass VMs. The architecture follows a clear separation of concerns:
- **Cloud-init**: Installs base dependencies (Docker, Python, system packages)
- **Terraform**: Provisions VMs and generates Ansible inventory
- **Ansible**: Configures Rancher on master and registers workers to the cluster

## Architecture

### Infrastructure Components

- **Multipass Provider**: Uses the `larstobi/multipass` provider (v1.4.2) to provision local VMs
- **Master Node**: Single VM (`rancher-master`) that will run Rancher management server
- **Worker Nodes**: Configurable number of worker VMs (default: 2) that join the Rancher cluster
- **Cloud-init Templates**: Lightweight templates that only install dependencies (Docker, Python3, system packages)
- **Ansible Playbooks**: Handle all post-installation configuration and cluster setup

### Key Terraform Resources

- `multipass_instance.rancher_master` (main.tf:2): Master node VM
- `multipass_instance.rancher_workers` (main.tf:16): Worker node VMs
- `local_file.cloudinit_master` (main.tf:36): Generates cloud-init YAML for master with SSH key
- `local_file.cloudinit_worker` (main.tf:44): Generates cloud-init YAML for workers with SSH key
- `local_file.ansible_inventory` (main.tf:52): Generates Ansible inventory with VM IPs

### Deployment Flow

1. **Cloud-init Phase** (automatic):
   - Templates in `cloud-init-scripts/*.tpl` are rendered with SSH public key
   - VMs boot and install: Docker, Python3, system packages
   - Kernel modules and sysctl settings configured for Kubernetes

2. **Ansible Phase** (fully automatic):
   - Master role (`ansible/roles/master/`):
     - Deploys Rancher container
     - Waits for API to be ready
     - Authenticates with Rancher API using bootstrap password
     - Creates Kubernetes cluster automatically via API
     - Extracts and saves registration command
   - Worker role (`ansible/roles/worker/`):
     - Fetches registration command from master node
     - Executes registration automatically
     - Verifies rancher-agent containers are running

### Ansible Structure

```
ansible/
├── ansible.cfg              # Ansible configuration
├── inventory.ini            # Auto-generated by Terraform
├── inventory.ini.template   # Template for inventory generation
├── requirements.yml         # Ansible collections (community.docker)
├── site.yml                # Main orchestration playbook
├── setup-cluster.yml       # Alternative simplified playbook
├── deploy-workers.sh       # Helper script to deploy workers
└── roles/
    ├── master/             # Rancher installation role
    │   ├── tasks/main.yml
    │   └── defaults/main.yml
    └── worker/             # Worker registration role
        ├── tasks/main.yml
        └── defaults/main.yml
```

## Common Commands

### Initial Setup and Deployment
```bash
# Full automated setup (Terraform + Ansible for complete cluster)
./setup.sh

# This will:
# 1. Provision VMs with Terraform
# 2. Wait for cloud-init to complete
# 3. Install and configure Rancher on master
# 4. Create Kubernetes cluster via Rancher API
# 5. Automatically register all worker nodes
# 6. Display Rancher URL and credentials
```

### Manual Terraform Only
```bash
terraform init
terraform plan
terraform apply
```

### Manual Ansible Execution
```bash
# Install Ansible collections first
cd ansible
ansible-galaxy collection install -r requirements.yml

# Install Rancher on master and create cluster
ansible-playbook -i inventory.ini site.yml --tags master

# Register all workers automatically
ansible-playbook -i inventory.ini site.yml --tags worker
```

### Fully Automated Cluster Setup
```bash
# One-command setup (master + workers)
cd ansible
ansible-playbook -i inventory.ini site.yml

# This will:
# 1. Deploy Rancher on master
# 2. Create cluster via API
# 3. Register all workers automatically
```

### Infrastructure Management
```bash
# View resources
terraform output
terraform show

# Destroy everything
terraform destroy -auto-approve
```

### VM Management
```bash
# List all VMs
multipass list

# Connect to nodes
multipass shell rancher-master
multipass shell worker-1

# Get master IP
terraform output -raw master_ip
```

### Rancher Operations
```bash
# View Rancher logs
multipass exec rancher-master -- docker logs -f rancher

# Get bootstrap password
multipass exec rancher-master -- cat /home/ubuntu/rancher-password.txt

# Check Rancher status
ansible master -i ansible/inventory.ini -m shell -a "docker ps | grep rancher"
```

### Ansible Debugging
```bash
# Test connectivity
ansible all -i ansible/inventory.ini -m ping

# Run with verbose output
ansible-playbook -i ansible/inventory.ini site.yml --tags master -vvv

# Check Docker on all nodes
ansible all -i ansible/inventory.ini -m shell -a "systemctl status docker"
```

## Configuration Variables

### Terraform Variables (variables.tf)
- `master_cpus`, `master_memory`, `master_disk`: Master node resources
- `worker_cpus`, `worker_memory`, `worker_disk`: Worker node resources
- `worker_count`: Number of worker nodes (default: 2)
- `ssh_public_key_path`: Path to SSH public key (default: `~/.ssh/id_rsa.pub`)

### Ansible Variables

**Master role** (`ansible/roles/master/defaults/main.yml`):
- `rancher_version`: Rancher version (default: "latest")
- `rancher_container_name`: Container name (default: "rancher")
- `rancher_data_dir`: Data directory (default: "/opt/rancher")
- `rancher_http_port`, `rancher_https_port`: Ports (default: 80, 443)
- `rancher_cluster_name`: Name for the Kubernetes cluster (default: "local-cluster")
- `rancher_cluster_type`: Type of cluster (default: "k3s", options: k3s, rke2, rke1)
  - **k3s** (recommended): Lightweight, fast, perfect for development/testing (uses ~512MB RAM)
  - **rke2**: Enterprise-ready, more resource intensive (2GB+ RAM)
  - **rke1**: Legacy, not recommended for new deployments
- `rancher_admin_password`: Admin password for Rancher (default: "AdminPassword123", must be 12+ characters)
- `rancher_registration_file`: Path where registration command is saved (default: "/home/ubuntu/cluster-registration-cmd.sh")

**Worker role** (`ansible/roles/worker/defaults/main.yml`):
- `rancher_registration_wait_timeout`: Timeout waiting for registration command (default: 600)
- `registration_check_interval`: Check interval (default: 10)

## Important Implementation Details

### Separation of Concerns

**Cloud-init** (cloud-init-scripts/*.tpl):
- Only installs base dependencies: Docker, Python3, curl, git, etc.
- Configures kernel modules and sysctl for Kubernetes
- Sets up Docker daemon configuration
- Adds SSH keys for remote access

**Ansible** (ansible/):
- Deploys and configures Rancher container on master
- Manages cluster creation and worker registration
- Handles all service-level configuration
- Provides idempotent operations (safe to re-run)

### Setup Script (setup.sh)

1. Validates dependencies: multipass, terraform, ansible
2. Ensures SSH key exists (generates if missing)
3. Runs `terraform apply` to create VMs
4. Waits for cloud-init to complete (checks Docker service)
5. Generates Ansible inventory from Terraform outputs
6. Runs Ansible playbook to install Rancher on master
7. Displays access information and next steps

### Rancher Master Setup (Ansible)

The master role performs the following tasks automatically:

1. **Container Deployment**:
   - Deploys Rancher as Docker container with privileged mode
   - Waits for HTTPS endpoint to respond (up to 5 minutes)
   - Extracts bootstrap password from container logs
   - Saves password to `/home/ubuntu/rancher-password.txt`

2. **API Authentication**:
   - Logs in to Rancher API using bootstrap password
   - Changes admin password to configured value
   - Generates API token for cluster operations
   - Sets server URL for external access

3. **Cluster Creation** (Fully Automatic):
   - Creates Kubernetes cluster via Rancher API
   - Uses configured cluster type (K3s by default - lightweight and fast)
   - Automatically selects latest available Kubernetes version
   - Waits for cluster registration token to be generated
   - Extracts registration command from API response
   - Saves registration command to file for workers to fetch

### Worker Registration (Fully Automatic)

Workers are now registered automatically without any UI interaction:

1. **Fetch Registration Command**:
   - Worker nodes SSH to master node
   - Retrieve registration command from `/home/ubuntu/cluster-registration-cmd.sh`
   - Wait with retries if master hasn't finished cluster creation yet

2. **Execute Registration**:
   - Run registration command on worker node
   - Wait for rancher-agent containers to start
   - Verify successful registration

No manual steps required - the entire cluster is provisioned end-to-end automatically!

### Ansible Inventory Generation

Terraform automatically generates `ansible/inventory.ini` with:
- Master node IP and hostname
- All worker nodes IPs and hostnames
- Common variables (Python interpreter, Rancher URL)
- Groups: `[master]`, `[workers]`, `[rancher:children]`

This ensures Ansible always has current IPs after Terraform provisioning.
